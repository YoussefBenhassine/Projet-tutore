# ğŸ“‹ User Stories LIME - Format Scrum

## ğŸ¯ User Story Principale

**En tant que** analyste ESG ou data scientist, **je veux** utiliser LIME (Local Interpretable Model-agnostic Explanations) pour expliquer les prÃ©dictions individuelles de score ESG, **afin de** comprendre quelles variables contribuent le plus Ã  chaque prÃ©diction spÃ©cifique et identifier les facteurs clÃ©s qui influencent le score ESG pour chaque entreprise.

---

## ğŸ“ User Stories DÃ©taillÃ©es

### User Story 1: Analyse Globale LIME
**En tant que** analyste ESG, **je veux** gÃ©nÃ©rer des explications LIME pour plusieurs exemples d'entreprises (1-10 observations), **afin de** obtenir une vue d'ensemble des facteurs qui influencent les prÃ©dictions ESG et identifier des patterns communs.

### User Story 2: Analyse Interactive LIME
**En tant que** analyste ESG, **je veux** sÃ©lectionner manuellement une observation spÃ©cifique et obtenir une explication LIME dÃ©taillÃ©e, **afin de** comprendre prÃ©cisÃ©ment pourquoi une entreprise particuliÃ¨re a reÃ§u un certain score ESG et quelles variables ont le plus d'impact.

### User Story 3: Statistiques Globales LIME
**En tant que** data scientist, **je veux** analyser l'importance moyenne des features sur un Ã©chantillon de 50 observations, **afin de** identifier les variables les plus importantes globalement et comprendre quelles features sont systÃ©matiquement influentes.

### User Story 4: Support du Clustering
**En tant que** analyste ESG, **je veux** que LIME dÃ©tecte et analyse automatiquement l'impact des clusters sur les prÃ©dictions, **afin de** comprendre comment l'appartenance Ã  un cluster influence le score ESG prÃ©dit.

### User Story 5: Visualisations LIME
**En tant que** utilisateur de l'application, **je veux** voir des visualisations claires (graphiques en barres avec code couleur) montrant l'impact positif/nÃ©gatif de chaque variable, **afin de** interprÃ©ter facilement les rÃ©sultats LIME sans expertise technique approfondie.

### User Story 6: Configuration LIME
**En tant que** data scientist, **je veux** pouvoir configurer le nombre de features Ã  expliquer et le nombre d'Ã©chantillons utilisÃ©s par LIME, **afin de** Ã©quilibrer la prÃ©cision des explications et le temps de calcul selon mes besoins.

---

## ğŸ¯ User Story Technique (DÃ©veloppeur)

**En tant que** dÃ©veloppeur, **je veux** implÃ©menter un module LIME robuste avec gestion d'erreurs et fallbacks, **afin de** fournir une fonctionnalitÃ© d'explicabilitÃ© fiable qui fonctionne mÃªme en cas de problÃ¨mes avec la bibliothÃ¨que LIME native.

---

## ğŸ“Š CritÃ¨res d'Acceptation

- âœ… L'utilisateur peut gÃ©nÃ©rer des explications LIME pour plusieurs exemples
- âœ… L'utilisateur peut sÃ©lectionner manuellement une observation Ã  expliquer
- âœ… Les visualisations montrent clairement l'impact positif/nÃ©gatif des variables
- âœ… Les clusters sont dÃ©tectÃ©s et leur impact est analysÃ©
- âœ… Les erreurs sont gÃ©rÃ©es gracieusement avec des messages informatifs
- âœ… L'interface est intuitive et ne nÃ©cessite pas d'expertise technique

---

## ğŸ”— Ã‰pique
**IA Explicable (XAI) - Module LIME**
