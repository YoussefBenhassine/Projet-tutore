"""
Streamlit dashboard for ESG dataset clustering pipeline.

This app provides:
- Dataset preview
- Preprocessing summary
- Clustering algorithm selection and execution
- Hyperparameter tuning
- Model comparison
- Visualization
- Cluster profiling
- Results download
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from typing import Dict, Optional
from xai_shap import render_shap_dashboard
from explainability.pdp_explainer import render_pdp_analysis

from xai_shap import render_shap_local_prediction
from Clustering.preprocessing import DataPreprocessor
from Clustering.clustering import ClusteringModels
from Clustering.optimization import HyperparameterOptimizer
from Clustering.evaluation import ClusteringEvaluator
from Clustering.labeling import ClusterProfiler
from training.train_regressors import RegressionTrainer
from utils.model_selection import ModelComparator
from evaluation.regression_metrics import RegressionMetrics
import pickle
import joblib
import os

# Page configuration
st.set_page_config(
    page_title="ESG Clustering Pipeline",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    </style>
""", unsafe_allow_html=True)

# Initialize session state
if 'preprocessor' not in st.session_state:
    st.session_state.preprocessor = None
if 'data_scaled' not in st.session_state:
    st.session_state.data_scaled = None
if 'data_pca_2d' not in st.session_state:
    st.session_state.data_pca_2d = None
if 'data_pca_3d' not in st.session_state:
    st.session_state.data_pca_3d = None
if 'models' not in st.session_state:
    st.session_state.models = {}
if 'labels' not in st.session_state:
    st.session_state.labels = {}
if 'best_model' not in st.session_state:
    st.session_state.best_model = None
if 'profiler' not in st.session_state:
    st.session_state.profiler = None
if 'original_data' not in st.session_state:
    st.session_state.original_data = None
if 'optimization_results' not in st.session_state:
    st.session_state.optimization_results = None
if 'comparison_df' not in st.session_state:
    st.session_state.comparison_df = None
if 'evaluator' not in st.session_state:
    st.session_state.evaluator = None
if 'regression_trainer' not in st.session_state:
    st.session_state.regression_trainer = None
if 'regression_results' not in st.session_state:
    st.session_state.regression_results = {}
if 'best_regression_model' not in st.session_state:
    st.session_state.best_regression_model = None
if 'regression_comparison_df' not in st.session_state:
    st.session_state.regression_comparison_df = None

def main():
    """Main application function."""
    
    st.markdown('<h1 class="main-header">üìä ESG Dataset Clustering Pipeline</h1>', 
                unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")
        
        # Dataset path
        dataset_path = st.text_input(
            "Dataset Path",
            value="data/esg_dataset.csv",
            help="Path to the ESG dataset CSV file"
        )
        
        st.divider()
        
        # Algorithm selection
        st.subheader("üîß Algorithm Selection")
        use_kmeans = st.checkbox("K-Means", value=True)
        use_gmm = st.checkbox("Gaussian Mixture Model (GMM)", value=True)
        use_hdbscan = st.checkbox("HDBSCAN", value=True)
        
        st.divider()
        
        # Manual hyperparameters
        st.subheader("üéõÔ∏è Manual Hyperparameters")
        
        # K-Means
        if use_kmeans:
            st.write("**K-Means**")
            kmeans_n_clusters = st.slider(
                "n_clusters",
                min_value=2,
                max_value=15,
                value=5,
                key="kmeans_n_clusters"
            )
        
        # GMM
        if use_gmm:
            st.write("**GMM**")
            gmm_n_components = st.slider(
                "n_components",
                min_value=2,
                max_value=15,
                value=5,
                key="gmm_n_components"
            )
            gmm_covariance_type = st.selectbox(
                "covariance_type",
                options=['full', 'tied', 'diag', 'spherical'],
                index=0,
                key="gmm_covariance_type"
            )
        
        # HDBSCAN
        if use_hdbscan:
            st.write("**HDBSCAN**")
            hdbscan_min_cluster_size = st.slider(
                "min_cluster_size",
                min_value=2,
                max_value=20,
                value=3,
                help="Valeurs plus petites = moins de bruit mais clusters plus petits. Recommand√©: 2-5 pour datasets < 200 points",
                key="hdbscan_min_cluster_size"
            )
            hdbscan_min_samples = st.slider(
                "min_samples",
                min_value=2,
                max_value=20,
                value=3,
                help="Valeurs plus petites = moins de bruit. Recommand√©: 2-4 pour datasets < 200 points",
                key="hdbscan_min_samples"
            )
            reassign_noise = st.checkbox(
                "R√©assigner les points de bruit au cluster le plus proche",
                value=False,
                help="Si activ√©, les points avec label -1 seront r√©assign√©s au cluster le plus proche",
                key="reassign_noise"
            )
        
        st.divider()
        
        # Action buttons
        st.subheader("üöÄ Actions")
        load_data_btn = st.button("üì• Load & Preprocess Data", use_container_width=True)
        optimize_btn = st.button("üîç Auto-Optimize Hyperparameters", use_container_width=True)
        run_clustering_btn = st.button("‚ñ∂Ô∏è Run Clustering", use_container_width=True)
        clear_cache_btn = st.button("üóëÔ∏è Clear Cache", use_container_width=True)
    
    # Main content
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
        "üìã Dataset", 
        "üîß Preprocessing", 
        "üéØ Clustering", 
        "üìä Results", 
        "üìà Visualizations",
        "üîÆ ESG Score Prediction",
        "‚öñÔ∏è Comparaison Clustering",
        "üß† Interpr√©tabilit√© (XAI)",
    ])
    
    # Tab 1: Dataset
    with tab1:
        st.header("Dataset Preview")
        
        if load_data_btn or st.session_state.preprocessor is not None:
            try:
                if st.session_state.preprocessor is None:
                    with st.spinner("Loading and preprocessing data..."):
                        preprocessor = DataPreprocessor(dataset_path)
                        data_scaled, data_pca_2d, data_pca_3d = preprocessor.preprocess_pipeline()
                        original_data = preprocessor.original_data
                        
                        st.session_state.preprocessor = preprocessor
                        st.session_state.data_scaled = data_scaled
                        st.session_state.data_pca_2d = data_pca_2d
                        st.session_state.data_pca_3d = data_pca_3d
                        st.session_state.original_data = original_data
                        st.session_state.profiler = ClusterProfiler(preprocessor.feature_names)
                        
                        st.success("‚úÖ Data loaded and preprocessed successfully!")
                
                # Display dataset info
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Total Samples", len(st.session_state.data_scaled))
                with col2:
                    st.metric("Features", len(st.session_state.data_scaled.columns))
                with col3:
                    st.metric("Missing Values", 
                             st.session_state.original_data.isnull().sum().sum())
                with col4:
                    st.metric("Data Shape", f"{st.session_state.data_scaled.shape[0]} √ó {st.session_state.data_scaled.shape[1]}")
                
                # Display original data preview
                st.subheader("Original Dataset Preview")
                st.dataframe(st.session_state.original_data.head(10), use_container_width=True)
                
                # Display scaled data preview
                st.subheader("Scaled Data Preview")
                st.dataframe(st.session_state.data_scaled.head(10), use_container_width=True)
                
            except Exception as e:
                st.error(f"‚ùå Error loading data: {str(e)}")
        else:
            st.info("üëÜ Click 'Load & Preprocess Data' in the sidebar to start.")
    
    # Tab 2: Preprocessing
    with tab2:
        st.header("Preprocessing Summary")
        
        if st.session_state.preprocessor is not None:
            summary = st.session_state.preprocessor.get_preprocessing_summary(
                st.session_state.original_data,
                st.session_state.data_scaled
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("Data Statistics")
                st.json({
                    "Original Shape": summary['original_shape'],
                    "Processed Shape": summary['processed_shape'],
                    "Missing Values (Before)": summary['missing_values_before'],
                    "Missing Values (After)": summary['missing_values_after'],
                    "Number of Features": summary['n_features'],
                    "Number of Samples": summary['n_samples']
                })
            
            with col2:
                st.subheader("Features")
                st.write(summary['features'])
            
            if 'pca_2d_variance' in summary:
                st.subheader("PCA Explained Variance (2D)")
                pca_info = summary['pca_2d_variance']
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("PC1 Variance", f"{pca_info['PC1']:.2%}")
                with col2:
                    st.metric("PC2 Variance", f"{pca_info['PC2']:.2%}")
                with col3:
                    st.metric("Total Variance", f"{pca_info['total']:.2%}")
        else:
            st.info("üëÜ Load data first to see preprocessing summary.")
    
    # Tab 3: Clustering
    with tab3:
        st.header("Clustering Configuration")
        
        if st.session_state.data_scaled is None:
            st.warning("‚ö†Ô∏è Please load data first.")
        else:
            # Elbow Method Section
            st.subheader("üìä M√©thode du Coude (Elbow Method)")
            st.write("La m√©thode du coude aide √† d√©terminer le nombre optimal de clusters pour K-Means en analysant l'inertie.")
            
            col_elbow1, col_elbow2 = st.columns([3, 1])
            with col_elbow1:
                max_k_elbow = st.slider(
                    "Nombre maximum de clusters √† tester",
                    min_value=3,
                    max_value=15,
                    value=10,
                    key="max_k_elbow"
                )
            with col_elbow2:
                compute_elbow_btn = st.button("üîç Calculer", key="compute_elbow", use_container_width=True)
            
            if compute_elbow_btn:
                with st.spinner("Calcul de la m√©thode du coude en cours..."):
                    try:
                        models_elbow = ClusteringModels()
                        elbow_results = models_elbow.compute_elbow_method(
                            st.session_state.data_scaled,
                            max_k=max_k_elbow
                        )
                        st.session_state.elbow_results = elbow_results
                        st.success(f"‚úÖ M√©thode du coude calcul√©e! K optimal sugg√©r√©: **{elbow_results['optimal_k']}**")
                    except Exception as e:
                        st.error(f"‚ùå Erreur lors du calcul: {str(e)}")
            
            # Display elbow method results
            if 'elbow_results' in st.session_state and st.session_state.elbow_results is not None:
                elbow_results = st.session_state.elbow_results
                
                # Create visualization
                from plotly.subplots import make_subplots
                
                fig_elbow = make_subplots(
                    rows=1, cols=2,
                    subplot_titles=('M√©thode du Coude (Inertie)', 'Score de Silhouette'),
                    specs=[[{"secondary_y": False}, {"secondary_y": False}]]
                )
                
                # Elbow plot (inertia)
                fig_elbow.add_trace(
                    go.Scatter(
                        x=elbow_results['k_values'],
                        y=elbow_results['inertias'],
                        mode='lines+markers',
                        name='Inertie',
                        line=dict(color='blue', width=2),
                        marker=dict(size=8)
                    ),
                    row=1, col=1
                )
                
                # Highlight optimal k
                optimal_k = elbow_results['optimal_k']
                if optimal_k in elbow_results['k_values']:
                    opt_idx = elbow_results['k_values'].index(optimal_k)
                    fig_elbow.add_trace(
                        go.Scatter(
                            x=[optimal_k],
                            y=[elbow_results['inertias'][opt_idx]],
                            mode='markers',
                            name=f'K optimal ({optimal_k})',
                            marker=dict(size=15, color='red', symbol='star')
                        ),
                        row=1, col=1
                    )
                
                # Silhouette score plot
                valid_sil = [(k, s) for k, s in zip(elbow_results['k_values'], elbow_results['silhouette_scores']) if s >= 0]
                if valid_sil:
                    k_vals_sil, sil_vals = zip(*valid_sil)
                    fig_elbow.add_trace(
                        go.Scatter(
                            x=list(k_vals_sil),
                            y=list(sil_vals),
                            mode='lines+markers',
                            name='Silhouette Score',
                            line=dict(color='green', width=2),
                            marker=dict(size=8)
                        ),
                        row=1, col=2
                    )
                    
                    # Highlight optimal k in silhouette plot
                    if optimal_k in k_vals_sil:
                        opt_sil_idx = list(k_vals_sil).index(optimal_k)
                        fig_elbow.add_trace(
                            go.Scatter(
                                x=[optimal_k],
                                y=[sil_vals[opt_sil_idx]],
                                mode='markers',
                                name=f'K optimal ({optimal_k})',
                                marker=dict(size=15, color='red', symbol='star')
                            ),
                            row=1, col=2
                        )
                
                fig_elbow.update_xaxes(title_text="Nombre de clusters (K)", row=1, col=1)
                fig_elbow.update_yaxes(title_text="Inertie (WCSS)", row=1, col=1)
                fig_elbow.update_xaxes(title_text="Nombre de clusters (K)", row=1, col=2)
                fig_elbow.update_yaxes(title_text="Score de Silhouette", row=1, col=2)
                fig_elbow.update_layout(height=500, showlegend=True, title_text="M√©thode du Coude - Analyse du Nombre Optimal de Clusters")
                
                st.plotly_chart(fig_elbow, use_container_width=True)
                
                # Summary table
                st.subheader("R√©sum√© des R√©sultats")
                summary_data = {
                    'K': elbow_results['k_values'],
                    'Inertie': [f"{i:.2f}" for i in elbow_results['inertias']],
                    'Score Silhouette': [f"{s:.3f}" if s >= 0 else "N/A" for s in elbow_results['silhouette_scores']]
                }
                df_elbow_summary = pd.DataFrame(summary_data)
                st.dataframe(df_elbow_summary, use_container_width=True)
                
                st.info(f"üí° **Recommandation**: Utilisez **K = {optimal_k}** clusters bas√© sur la m√©thode du coude. "
                       f"Vous pouvez copier cette valeur dans le slider 'n_clusters' de K-Means dans la sidebar.")
            
            st.divider()
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("Auto-Optimization")
                
                # Show existing optimization results if available
                if st.session_state.optimization_results is not None:
                    st.info("‚úÖ Optimization results available below. Click 'Auto-Optimize' again to re-run.")
                    st.subheader("Previous Optimization Results")
                    for model_name, params in st.session_state.optimization_results.items():
                        with st.expander(f"{model_name.upper()} - Optimal Parameters"):
                            st.json(params)
                            if model_name == 'kmeans':
                                st.write(f"üí° Use **n_clusters = {params['n_clusters']}** in sidebar")
                            elif model_name == 'gmm':
                                st.write(f"üí° Use **n_components = {params['n_components']}** and **covariance_type = '{params['covariance_type']}'** in sidebar")
                            elif model_name == 'hdbscan':
                                st.write(f"üí° Use **min_cluster_size = {params['min_cluster_size']}** and **min_samples = {params['min_samples']}** in sidebar")
                
                if optimize_btn:
                    with st.spinner("Optimizing hyperparameters... This may take a while."):
                        try:
                            optimizer = HyperparameterOptimizer()
                            
                            results = {}
                            if use_kmeans:
                                st.write("Optimizing K-Means...")
                                results['kmeans'] = optimizer.optimize_kmeans(st.session_state.data_scaled)
                            
                            if use_gmm:
                                st.write("Optimizing GMM...")
                                results['gmm'] = optimizer.optimize_gmm(st.session_state.data_scaled)
                            
                            if use_hdbscan:
                                st.write("Optimizing HDBSCAN...")
                                results['hdbscan'] = optimizer.optimize_hdbscan(st.session_state.data_scaled)
                            
                            st.session_state.optimization_results = results
                            st.success("‚úÖ Optimization complete!")
                            st.rerun()
                                
                        except Exception as e:
                            st.error(f"‚ùå Optimization error: {str(e)}")
            
            with col2:
                st.subheader("Manual Clustering")
                if run_clustering_btn:
                    with st.spinner("Running clustering algorithms..."):
                        try:
                            models = ClusteringModels()
                            labels_dict = {}
                            
                            if use_kmeans:
                                st.write("Running K-Means...")
                                labels_kmeans = models.fit_kmeans(
                                    st.session_state.data_scaled,
                                    n_clusters=kmeans_n_clusters
                                )
                                labels_dict['kmeans'] = labels_kmeans
                            
                            if use_gmm:
                                st.write("Running GMM...")
                                labels_gmm = models.fit_gmm(
                                    st.session_state.data_scaled,
                                    n_components=gmm_n_components,
                                    covariance_type=gmm_covariance_type
                                )
                                labels_dict['gmm'] = labels_gmm
                            
                            if use_hdbscan:
                                st.write("Running HDBSCAN...")
                                labels_hdbscan = models.fit_hdbscan(
                                    st.session_state.data_scaled,
                                    min_cluster_size=hdbscan_min_cluster_size,
                                    min_samples=hdbscan_min_samples
                                )
                                
                                # Reassign noise if requested
                                if reassign_noise and -1 in labels_hdbscan:
                                    n_noise_before = int(np.sum(labels_hdbscan == -1))
                                    labels_hdbscan = models.reassign_noise_points(
                                        st.session_state.data_scaled,
                                        labels_hdbscan
                                    )
                                    n_noise_after = int(np.sum(labels_hdbscan == -1))
                                    st.info(f"‚úÖ {n_noise_before} points de bruit r√©assign√©s aux clusters les plus proches")
                                
                                labels_dict['hdbscan'] = labels_hdbscan
                            
                            st.session_state.models = models
                            st.session_state.labels = labels_dict
                            
                            # Evaluate models
                            evaluator = ClusteringEvaluator()
                            comparison_df = evaluator.compare_models(
                                st.session_state.data_scaled,
                                models,
                                labels_dict
                            )
                            
                            if not comparison_df.empty:
                                best_model = evaluator.select_best_model(comparison_df)
                                st.session_state.best_model = best_model
                                st.session_state.evaluator = evaluator
                                st.session_state.comparison_df = comparison_df
                                st.success(f"‚úÖ Clustering complete! Best model: {best_model.upper()}")
                            else:
                                st.warning("‚ö†Ô∏è No valid models to compare.")
                                
                        except Exception as e:
                            st.error(f"‚ùå Clustering error: {str(e)}")
    
    # Tab 4: Results
    with tab4:
        st.header("Clustering Results")
        
        if 'comparison_df' not in st.session_state or st.session_state.comparison_df is None:
            st.info("üëÜ Run clustering first to see results.")
        else:
            # Model comparison
            st.subheader("Model Comparison")
            st.dataframe(st.session_state.comparison_df, use_container_width=True)
            
            # Best model
            if st.session_state.best_model:
                st.success(f"üèÜ Best Model: **{st.session_state.best_model.upper()}**")
                
                # Show cluster information for best model
                if st.session_state.best_model in st.session_state.labels:
                    best_labels = st.session_state.labels[st.session_state.best_model]
                    unique_labels = set(best_labels)
                    n_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)
                    n_noise = int(np.sum(best_labels == -1)) if -1 in best_labels else 0
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Nombre de clusters", n_clusters)
                    with col2:
                        if n_noise > 0:
                            noise_ratio = n_noise / len(best_labels) * 100
                            st.metric("Points de bruit (-1)", n_noise)
                            st.caption(f"‚ÑπÔ∏è {noise_ratio:.1f}% du dataset")
                            
                            if noise_ratio > 30:
                                st.error("‚ö†Ô∏è Trop de bruit! R√©duisez min_cluster_size et min_samples")
                            elif noise_ratio > 15:
                                st.warning("‚ö†Ô∏è Beaucoup de bruit. Consid√©rez ajuster les param√®tres")
                    
                    if n_noise > 0:
                        noise_ratio = n_noise / len(best_labels) * 100
                        explanation = f"üìå **Explication**: Le mod√®le {st.session_state.best_model.upper()} a identifi√© **{n_clusters} clusters** "
                        explanation += f"(labels: {sorted([l for l in unique_labels if l != -1])}) et **{n_noise} points de bruit** "
                        explanation += f"({noise_ratio:.1f}% - label: -1). Le label -1 n'est pas un cluster mais repr√©sente les outliers."
                        
                        if noise_ratio > 30:
                            st.error(explanation)
                            st.warning("üí° **Solutions**: 1) R√©duisez `min_cluster_size` √† 2-3 et `min_samples` √† 2-3 dans la sidebar, "
                                     "2) Relancez le clustering, 3) Ou activez 'R√©assigner les points de bruit'")
                        else:
                            st.info(explanation)
            
            st.divider()
            
            # Cluster profiles
            if st.session_state.labels and st.session_state.best_model:
                st.subheader("Cluster Profiles")
                
                best_labels = st.session_state.labels[st.session_state.best_model]
                profiles = st.session_state.profiler.profile_clusters(
                    st.session_state.data_scaled,
                    best_labels
                )
                
                st.dataframe(profiles, use_container_width=True)
                
                # Cluster interpretations
                st.subheader("Cluster Interpretations")
                
                # Check for noise points
                n_noise = int(np.sum(best_labels == -1)) if -1 in best_labels else 0
                if n_noise > 0:
                    st.warning(f"‚ö†Ô∏è **Note**: {n_noise} points ont le label -1 (bruit/outliers) et ne sont pas inclus dans les profils de clusters ci-dessous.")
                
                interpretations = st.session_state.profiler.get_cluster_interpretations(
                    st.session_state.data_scaled,
                    best_labels
                )
                
                for cluster_id, interpretation in interpretations.items():
                    with st.expander(f"Cluster {cluster_id} (Size: {interpretation['size']})"):
                        st.write("**Top Features:**")
                        for feat_info in interpretation.get('top_features', []):
                            st.write(f"- {feat_info['feature']}: {feat_info['value']:.2f}")
                        
                        st.write("**Bottom Features:**")
                        for feat_info in interpretation.get('bottom_features', []):
                            st.write(f"- {feat_info['feature']}: {feat_info['value']:.2f}")
                
                # Cluster naming
                st.divider()
                st.subheader("üè∑Ô∏è Nommage des Clusters")
                
                # Calculate dimension scores (using original data for interpretable scores)
                # We need to get the original data without Company_ID and Sector
                original_features = st.session_state.original_data.drop(
                    columns=['Company_ID', 'Sector'], errors='ignore'
                )
                dimension_scores = st.session_state.profiler.calculate_dimension_scores(
                    original_features,
                    best_labels,
                    use_original_scale=True
                )
                
                st.write("**Scores par dimension ESG par cluster:**")
                st.dataframe(dimension_scores, use_container_width=True)
                
                # Generate cluster names (using original data for interpretable scores)
                cluster_names = st.session_state.profiler.generate_cluster_names(
                    original_features,
                    best_labels
                )
                
                st.write("**Noms g√©n√©r√©s automatiquement:**")
                names_df = pd.DataFrame([
                    {'Cluster': k, 'Nom': v} 
                    for k, v in sorted(cluster_names.items())
                ])
                st.dataframe(names_df, use_container_width=True)
                
                # Option to customize names
                with st.expander("‚úèÔ∏è Personnaliser les noms des clusters"):
                    custom_names = {}
                    for cluster_id in sorted(cluster_names.keys()):
                        default_name = cluster_names[cluster_id]
                        custom_name = st.text_input(
                            f"Cluster {cluster_id}",
                            value=default_name,
                            key=f"custom_name_{cluster_id}"
                        )
                        if custom_name != default_name:
                            custom_names[cluster_id] = custom_name
                    
                    if custom_names:
                        st.info("üí° Les noms personnalis√©s seront utilis√©s dans le dataset t√©l√©charg√©")
                
                # Download results
                st.divider()
                st.subheader("Download Results")
                
                # Create labeled dataset with cluster names
                if custom_names:
                    labeled_data = st.session_state.profiler.assign_cluster_names_to_data(
                        st.session_state.original_data,
                        best_labels,
                        scaled_data=original_features,
                        custom_names=custom_names
                    )
                else:
                    labeled_data = st.session_state.profiler.assign_cluster_names_to_data(
                        st.session_state.original_data,
                        best_labels,
                        scaled_data=original_features
                    )
                
                csv = labeled_data.to_csv(index=False)
                st.download_button(
                    label="üì• Download Labeled Dataset with Cluster Names (CSV)",
                    data=csv,
                    file_name="esg_clustered_results.csv",
                    mime="text/csv"
                )
                
                # Show preview of labeled data
                st.write("**Aper√ßu du dataset avec noms de clusters:**")
                st.dataframe(labeled_data[['Company_ID', 'Sector', 'ESG_Score', 'Cluster', 'Cluster_Name']].head(10), 
                           use_container_width=True)
    
    # Tab 5: Visualizations
    with tab5:
        st.header("üìà Visualizations")
        
        # Check if clustered results dataset exists
        clustered_dataset_path = "data/esg_clustered_results.csv"
        
        if not os.path.exists(clustered_dataset_path):
            st.warning("‚ö†Ô∏è Clustered results dataset not found. Please run clustering first and download the results.")
        else:
            # Load the dataset
            try:
                clustered_df = pd.read_csv(clustered_dataset_path)
                st.success(f"‚úÖ Dataset loaded: {len(clustered_df)} samples")
                
                # Check if Cluster column exists
                if 'Cluster' not in clustered_df.columns:
                    st.error("‚ùå Cluster column not found in the dataset. Please run clustering first.")
                else:
                    # Prepare data for visualization
                    from sklearn.preprocessing import StandardScaler
                    from sklearn.decomposition import PCA
                    from sklearn.impute import SimpleImputer
                    
                    # Extract feature columns (exclude metadata)
                    exclude_cols = ['Company_ID', 'Sector', 'Cluster_Name', 'ESG_Score', 'Cluster']
                    feature_cols = [col for col in clustered_df.columns 
                                   if col not in exclude_cols and clustered_df[col].dtype in ['int64', 'float64']]
                    
                    if len(feature_cols) == 0:
                        st.error("‚ùå No numeric features found for visualization.")
                    else:
                        # Extract features
                        X = clustered_df[feature_cols].copy()
                        
                        # Handle missing values
                        imputer = SimpleImputer(strategy='mean')
                        X_imputed = pd.DataFrame(
                            imputer.fit_transform(X),
                            columns=X.columns,
                            index=X.index
                        )
                        
                        # Scale features
                        scaler = StandardScaler()
                        X_scaled = pd.DataFrame(
                            scaler.fit_transform(X_imputed),
                            columns=X_imputed.columns,
                            index=X_imputed.index
                        )
                        
                        # Get cluster labels
                        cluster_labels = clustered_df['Cluster'].astype(int).values
                        
                        # Calculate PCA
                        pca_2d = PCA(n_components=2, random_state=42)
                        pca_3d = PCA(n_components=3, random_state=42)
                        
                        pca_2d_result = pca_2d.fit_transform(X_scaled)
                        pca_3d_result = pca_3d.fit_transform(X_scaled)
                        
                        # Get cluster statistics
                        unique_clusters = np.unique(cluster_labels)
                        n_clusters = len(unique_clusters) - (1 if -1 in unique_clusters else 0)
                        n_noise = np.sum(cluster_labels == -1) if -1 in unique_clusters else 0
                        
                        # Display cluster info
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Total Samples", len(clustered_df))
                        with col2:
                            st.metric("Number of Clusters", n_clusters)
                        with col3:
                            st.metric("Noise Points", n_noise)
                        
                        if n_noise > 0:
                            noise_pct = (n_noise / len(cluster_labels)) * 100
                            if noise_pct > 30:
                                st.error(f"‚ö†Ô∏è High noise ratio: {noise_pct:.1f}%")
                            elif noise_pct > 15:
                                st.warning(f"‚ö†Ô∏è Moderate noise ratio: {noise_pct:.1f}%")
                            else:
                                st.info(f"‚ÑπÔ∏è Noise ratio: {noise_pct:.1f}%")
                        
                        st.divider()
                        
                        # 2D PCA Visualization
                        st.subheader("üîµ 2D PCA Visualization")
                        
                        # Create DataFrame for easier plotting
                        pca_2d_df = pd.DataFrame({
                            'PC1': pca_2d_result[:, 0],
                            'PC2': pca_2d_result[:, 1],
                            'Cluster': cluster_labels
                        })
                        
                        # Calculate explained variance
                        explained_var_2d = pca_2d.explained_variance_ratio_
                        total_var_2d = explained_var_2d.sum() * 100
                        
                        # Create 2D plot using plotly express
                        fig_2d = px.scatter(
                            pca_2d_df,
                            x='PC1',
                            y='PC2',
                            color='Cluster',
                            color_discrete_sequence=px.colors.qualitative.Set3,
                            title=f"2D PCA Plot ({n_clusters} clusters" + 
                                  (f" + {n_noise} noise)" if n_noise > 0 else "") + 
                                  f" - {total_var_2d:.1f}% variance explained",
                            labels={
                                'PC1': f'PC1 ({explained_var_2d[0]*100:.1f}% variance)',
                                'PC2': f'PC2 ({explained_var_2d[1]*100:.1f}% variance)'
                            },
                            hover_data=['Cluster']
                        )
                        
                        # Update marker size and style
                        fig_2d.update_traces(
                            marker=dict(size=7, opacity=0.7, line=dict(width=0.5, color='white')),
                            selector=dict(mode='markers')
                        )
                        
                        # Update layout
                        fig_2d.update_layout(
                            width=900,
                            height=700,
                            hovermode='closest'
                        )
                        
                        st.plotly_chart(fig_2d, use_container_width=True)
                        
                        st.divider()
                        
                        # 3D PCA Visualization
                        st.subheader("üî∑ 3D PCA Visualization")
                        
                        # Create DataFrame for easier plotting
                        pca_3d_df = pd.DataFrame({
                            'PC1': pca_3d_result[:, 0],
                            'PC2': pca_3d_result[:, 1],
                            'PC3': pca_3d_result[:, 2],
                            'Cluster': cluster_labels
                        })
                        
                        # Calculate explained variance for 3D
                        explained_var_3d = pca_3d.explained_variance_ratio_
                        total_var_3d = explained_var_3d.sum() * 100
                        
                        # Create 3D plot using plotly express
                        fig_3d = px.scatter_3d(
                            pca_3d_df,
                            x='PC1',
                            y='PC2',
                            z='PC3',
                            color='Cluster',
                            color_discrete_sequence=px.colors.qualitative.Set3,
                            title=f"3D PCA Plot ({n_clusters} clusters" + 
                                  (f" + {n_noise} noise)" if n_noise > 0 else "") + 
                                  f" - {total_var_3d:.1f}% variance explained",
                            labels={
                                'PC1': f'PC1 ({explained_var_3d[0]*100:.1f}% variance)',
                                'PC2': f'PC2 ({explained_var_3d[1]*100:.1f}% variance)',
                                'PC3': f'PC3 ({explained_var_3d[2]*100:.1f}% variance)'
                            },
                            hover_data=['Cluster']
                        )
                        
                        # Update marker size and style
                        fig_3d.update_traces(
                            marker=dict(size=4, opacity=0.7, line=dict(width=0.5, color='white')),
                            selector=dict(mode='markers')
                        )
                        
                        # Update layout
                        fig_3d.update_layout(
                            width=900,
                            height=700,
                            hovermode='closest',
                            scene=dict(bgcolor='rgba(0,0,0,0)')
                        )
                        
                        st.plotly_chart(fig_3d, use_container_width=True)
                        
                        st.divider()
                        
                        # Cluster Size Distribution
                        st.subheader("üìä Cluster Size Distribution")
                        
                        cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()
                        
                        # Separate noise from clusters
                        if -1 in cluster_counts.index:
                            noise_count = cluster_counts[-1]
                            cluster_counts_clean = cluster_counts.drop(-1)
                        else:
                            cluster_counts_clean = cluster_counts
                            noise_count = 0
                        
                        # Create bar chart
                        fig_bar = go.Figure()
                        
                        fig_bar.add_trace(go.Bar(
                            x=cluster_counts_clean.index.astype(str),
                            y=cluster_counts_clean.values,
                            marker_color='lightblue',
                            text=cluster_counts_clean.values,
                            textposition='outside',
                            hovertemplate='Cluster: %{x}<br>Count: %{y}<extra></extra>'
                        ))
                        
                        fig_bar.update_layout(
                            title=f"Cluster Sizes (Total: {len(cluster_counts_clean)} clusters)",
                            xaxis_title='Cluster ID',
                            yaxis_title='Number of Samples',
                            width=800,
                            height=500
                        )
                        
                        st.plotly_chart(fig_bar, use_container_width=True)
                        
                        # Display cluster size table
                        cluster_size_df = pd.DataFrame({
                            'Cluster': cluster_counts_clean.index.astype(int),
                            'Size': cluster_counts_clean.values,
                            'Percentage': (cluster_counts_clean.values / len(cluster_labels) * 100).round(2)
                        })
                        
                        if noise_count > 0:
                            noise_row = pd.DataFrame({
                                'Cluster': [-1],
                                'Size': [noise_count],
                                'Percentage': [(noise_count / len(cluster_labels) * 100).round(2)]
                            })
                            cluster_size_df = pd.concat([cluster_size_df, noise_row], ignore_index=True)
                        
                        st.dataframe(cluster_size_df, use_container_width=True)
                        
            except Exception as e:
                st.error(f"‚ùå Error loading or processing data: {str(e)}")
                with st.expander("üîç Error Details"):
                    import traceback
                    st.code(traceback.format_exc())
    
    # Tab 6: ESG Score Prediction
    with tab6:
        st.header("üîÆ ESG Score Prediction")
        
        # Use clustered results dataset for prediction
        clustered_dataset_path = "data/esg_clustered_results.csv"
        
        # Check if clustered results file exists
        if not os.path.exists(clustered_dataset_path):
            st.warning("‚ö†Ô∏è Clustered results dataset not found. Please run clustering first and download the results.")
            st.info("üí° **Note**: The prediction module uses `data/esg_clustered_results.csv` which includes cluster labels. "
                   "Make sure to run clustering and download the results first.")
        else:
            st.info("‚ÑπÔ∏è **Using dataset**: `data/esg_clustered_results.csv` (includes cluster labels from clustering phase)")
            # Configuration section
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("Model Selection")
                use_rf = st.checkbox("Random Forest", value=True)
                use_lgbm = st.checkbox("LightGBM", value=True)
                
                st.subheader("Training Configuration")
                use_optimization = st.checkbox("Use Hyperparameter Optimization", value=True)
                n_trials = st.slider("Optimization Trials", min_value=10, max_value=100, value=50, 
                                   disabled=not use_optimization)
                cv_folds = st.slider("Cross-Validation Folds", min_value=3, max_value=10, value=5)
                include_clusters = st.checkbox("Include Cluster Labels as Features", value=True)
            
            with col2:
                st.subheader("Target Variable")
                # Load clustered dataset to get available columns
                try:
                    clustered_df = pd.read_csv(clustered_dataset_path, nrows=1)
                    available_columns = clustered_df.columns.tolist()
                    target_column = st.selectbox(
                        "Select Target Column",
                        options=available_columns,
                        index=available_columns.index('ESG_Score') 
                              if 'ESG_Score' in available_columns else 0
                    )
                except Exception as e:
                    st.error(f"Error loading clustered dataset: {str(e)}")
                    target_column = 'ESG_Score'
                
                st.subheader("Test Split")
                test_size = st.slider("Test Set Size", min_value=0.1, max_value=0.4, value=0.2, step=0.05)
            
            st.divider()
            
            # Train models button
            train_btn = st.button("üöÄ Train Regression Models", use_container_width=True, type="primary")
            
            if train_btn:
                with st.spinner("Training regression models... This may take a while."):
                    try:
                        # Initialize trainer with clustered results dataset
                        trainer = RegressionTrainer(
                            dataset_path=clustered_dataset_path,
                            target_column=target_column,
                            test_size=test_size,
                            random_state=42
                        )
                        
                        # Load and prepare data (Cluster column will be used if include_clusters=True)
                        X, y = trainer.load_and_prepare_data(
                            include_cluster_labels=include_clusters,
                            cluster_labels=None  # Cluster column is already in the dataset
                        )
                        trainer.split_data(X, y)
                        
                        st.session_state.regression_trainer = trainer
                        results = {}
                        
                        # Train Random Forest
                        if use_rf:
                            with st.spinner("Training Random Forest..."):
                                rf_results = trainer.train_random_forest(
                                    use_optimization=use_optimization,
                                    n_trials=n_trials,
                                    cv=cv_folds
                                )
                                results['Random Forest'] = rf_results
                        
                        # Train LightGBM
                        if use_lgbm:
                            with st.spinner("Training LightGBM..."):
                                lgbm_results = trainer.train_lightgbm(
                                    use_optimization=use_optimization,
                                    n_trials=n_trials,
                                    cv=cv_folds
                                )
                                if lgbm_results is not None:
                                    results['LightGBM'] = lgbm_results
                                else:
                                    st.warning("LightGBM training failed. Install with: pip install lightgbm")
                        
                        if results:
                            st.session_state.regression_results = results
                            
                            # Create comparison DataFrame
                            comparator = ModelComparator()
                            comparison_df = comparator.create_comparison_dataframe(results)
                            st.session_state.regression_comparison_df = comparison_df
                            
                            # Select best model
                            best_model_name = comparator.select_best_model(results, metric='r2_score', use_cv=True)
                            st.session_state.best_regression_model = best_model_name
                            
                            st.success(f"‚úÖ Training complete! Best model: **{best_model_name}**")
                            st.rerun()
                        else:
                            st.error("‚ùå No models were trained. Please select at least one model.")
                    
                    except Exception as e:
                        st.error(f"‚ùå Training error: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())
            
            # Display results if available
            if st.session_state.regression_results:
                st.divider()
                
                # Model Comparison
                st.subheader("üìä Model Comparison")
                
                if st.session_state.regression_comparison_df is not None:
                    st.dataframe(st.session_state.regression_comparison_df, use_container_width=True)
                    
                    # Best model indicator
                    if st.session_state.best_regression_model:
                        st.success(f"üèÜ Best Model: **{st.session_state.best_regression_model}**")
                
                # Visualizations
                st.subheader("üìà Model Performance Visualizations")
                
                comparator = ModelComparator()
                
                # Comprehensive comparison
                fig_comprehensive = comparator.create_comprehensive_comparison(st.session_state.regression_results)
                st.plotly_chart(fig_comprehensive, use_container_width=True)
                
                # Radar chart
                col_viz1, col_viz2 = st.columns(2)
                with col_viz1:
                    st.write("**Radar Chart (CV Metrics)**")
                    fig_radar = comparator.create_radar_chart(st.session_state.regression_results, use_cv=True)
                    st.plotly_chart(fig_radar, use_container_width=True)
                
                with col_viz2:
                    st.write("**R¬≤ Score Comparison**")
                    fig_r2 = comparator.create_bar_comparison(
                        st.session_state.regression_results, 
                        metric='r2_score',
                        use_cv=True
                    )
                    st.plotly_chart(fig_r2, use_container_width=True)
                
                st.divider()
                
                # Model-specific details
                st.subheader("üîç Model Details")
                
                model_selection = st.selectbox(
                    "Select Model to View Details",
                    options=list(st.session_state.regression_results.keys())
                )
                
                model_results = st.session_state.regression_results[model_selection]
                
                # Metrics
                col_met1, col_met2, col_met3, col_met4 = st.columns(4)
                test_metrics = model_results.get('test_metrics', {})
                with col_met1:
                    st.metric("R¬≤ Score (Test)", f"{test_metrics.get('r2_score', 0):.4f}")
                with col_met2:
                    st.metric("RMSE (Test)", f"{test_metrics.get('rmse', 0):.4f}")
                with col_met3:
                    st.metric("MAE (Test)", f"{test_metrics.get('mae', 0):.4f}")
                with col_met4:
                    st.metric("MAPE (Test)", f"{test_metrics.get('mape', 0):.2f}%")
                
                # Prediction vs True values scatter plot
                st.subheader("üìâ Prediction vs True Values")
                col_pred1, col_pred2 = st.columns(2)
                
                with col_pred1:
                    st.write("**Test Set**")
                    fig_test = go.Figure()
                    fig_test.add_trace(go.Scatter(
                        x=model_results['true_values']['test'],
                        y=model_results['predictions']['test'],
                        mode='markers',
                        name='Predictions',
                        marker=dict(color='blue', opacity=0.6)
                    ))
                    # Perfect prediction line
                    min_val = min(min(model_results['true_values']['test']), 
                                 min(model_results['predictions']['test']))
                    max_val = max(max(model_results['true_values']['test']), 
                                 max(model_results['predictions']['test']))
                    fig_test.add_trace(go.Scatter(
                        x=[min_val, max_val],
                        y=[min_val, max_val],
                        mode='lines',
                        name='Perfect Prediction',
                        line=dict(color='red', dash='dash')
                    ))
                    fig_test.update_layout(
                        title="Prediction vs True Values (Test Set)",
                        xaxis_title="True Values",
                        yaxis_title="Predicted Values",
                        showlegend=True
                    )
                    st.plotly_chart(fig_test, use_container_width=True)
                
                with col_pred2:
                    st.write("**Residuals Distribution**")
                    residuals = model_results['true_values']['test'] - model_results['predictions']['test']
                    fig_residuals = go.Figure()
                    fig_residuals.add_trace(go.Histogram(
                        x=residuals,
                        nbinsx=30,
                        name='Residuals',
                        marker_color='green'
                    ))
                    fig_residuals.update_layout(
                        title="Residuals Distribution (Test Set)",
                        xaxis_title="Residuals (True - Predicted)",
                        yaxis_title="Frequency",
                        showlegend=False
                    )
                    st.plotly_chart(fig_residuals, use_container_width=True)
                
                # Feature importance
                st.subheader("üéØ Feature Importance")
                feature_importance = model_results.get('feature_importance')
                if feature_importance is not None:
                    fig_importance = px.bar(
                        feature_importance.head(15),
                        x='importance',
                        y='feature',
                        orientation='h',
                        title="Top 15 Most Important Features",
                        labels={'importance': 'Importance Score', 'feature': 'Feature'}
                    )
                    fig_importance.update_layout(yaxis={'categoryorder': 'total ascending'})
                    st.plotly_chart(fig_importance, use_container_width=True)
                    
                    st.dataframe(feature_importance, use_container_width=True)
                
                st.divider()
                
                # Prediction on new data
                st.subheader("üîÆ Predict New ESG Scores")
                
                if st.session_state.regression_trainer and st.session_state.best_regression_model:
                    best_model_obj = st.session_state.regression_results[st.session_state.best_regression_model]['model']
                    
                    # Get feature names
                    feature_names = st.session_state.regression_trainer.feature_names
                    
                    # Load clustered dataset to get reference values
                    clustered_df_ref = pd.read_csv(clustered_dataset_path)
                    
                    # Create input form
                    with st.form("prediction_form"):
                        st.write("Enter feature values for prediction:")
                        input_data = {}
                        
                        # Create columns for inputs
                        n_cols = 3
                        cols = st.columns(n_cols)
                        
                        for idx, feature in enumerate(feature_names):
                            col_idx = idx % n_cols
                            with cols[col_idx]:
                                if feature == 'Cluster' or feature == 'Cluster_Label':
                                    # Get unique cluster labels from clustered dataset
                                    if 'Cluster' in clustered_df_ref.columns:
                                        unique_clusters = sorted(clustered_df_ref['Cluster'].unique())
                                    else:
                                        unique_clusters = [0, 1, 2, 3, 4]  # Fallback
                                    input_data[feature] = st.selectbox(
                                        f"{feature}",
                                        options=unique_clusters,
                                        key=f"input_{feature}"
                                    )
                                else:
                                    # Get min/max from clustered dataset for scaling reference
                                    if feature in clustered_df_ref.columns:
                                        min_val = float(clustered_df_ref[feature].min())
                                        max_val = float(clustered_df_ref[feature].max())
                                        mean_val = float(clustered_df_ref[feature].mean())
                                    else:
                                        min_val = 0
                                        max_val = 100
                                        mean_val = 50
                                    
                                    input_data[feature] = st.number_input(
                                        f"{feature}",
                                        min_value=min_val,
                                        max_value=max_val,
                                        value=mean_val,
                                        key=f"input_{feature}"
                                    )
                        
                        predict_btn = st.form_submit_button("üîÆ Predict ESG Score", use_container_width=True)
                        
                        if predict_btn:
                            try:
                                # Create DataFrame from input
                                input_df = pd.DataFrame([input_data])
                                
                                # Preprocess input using trainer's scaler and imputer
                                if st.session_state.regression_trainer:
                                    trainer = st.session_state.regression_trainer
                                    
                                    # Get ESG feature columns (exclude Cluster if present, we'll add it back)
                                    cluster_val = None
                                    if 'Cluster' in input_df.columns:
                                        cluster_val = input_df['Cluster'].values[0]
                                        input_df_features = input_df.drop(columns=['Cluster'])
                                    else:
                                        input_df_features = input_df.copy()
                                    
                                    # Impute missing values
                                    input_imputed = pd.DataFrame(
                                        trainer.imputer.transform(input_df_features),
                                        columns=input_df_features.columns,
                                        index=input_df_features.index
                                    )
                                    
                                    # Scale features
                                    input_scaled = pd.DataFrame(
                                        trainer.scaler.transform(input_imputed),
                                        columns=input_imputed.columns,
                                        index=input_imputed.index
                                    )
                                    
                                    # Add Cluster back if it was included
                                    if cluster_val is not None:
                                        input_scaled['Cluster'] = cluster_val
                                    
                                    # Ensure column order matches training data
                                    input_scaled = input_scaled[feature_names]
                                    
                                    # Make prediction
                                    prediction = best_model_obj.predict(input_scaled)
                                    # Make prediction

# =========================
# üéØ R√©sultat de pr√©diction
# =========================
                                    st.success(f"‚úÖ Predicted ESG Score: {prediction[0]:.2f}")

# =========================
# üß† SHAP LOCAL EXPLANATION
# =========================


                                    with st.expander("üß† Pourquoi ce score ESG ? (SHAP)"):
                                      render_shap_local_prediction(
                                      best_model=best_model_obj,
                                      trainer=trainer,
                                      X_single=input_scaled,
                                      prediction_value=prediction[0]
                                        )

# =========================
# üìã D√©tails pr√©diction
# =========================
                                  
                  

                                    # Show prediction details
                                    with st.expander("üìã Prediction Details"):
                                        st.write("**Input Features:**")
                                        st.dataframe(input_df, use_container_width=True)
                                        st.write(f"**Predicted ESG Score:** {prediction[0]:.4f}")
                                else:
                                    st.error("‚ùå Trainer not available. Please train models first.")
                                
                            except Exception as e:
                                st.error(f"‚ùå Prediction error: {str(e)}")
                                import traceback
                                st.code(traceback.format_exc())
                
                # Download model
                st.divider()
                st.subheader("üíæ Save Model")
                
                if st.session_state.best_regression_model:
                    best_model_obj = st.session_state.regression_results[st.session_state.best_regression_model]['model']
                    
                    # Save model using joblib
                    model_path = "models/best_model.pkl"
                    os.makedirs("models", exist_ok=True)
                    
                    # Extract the underlying scikit-learn/LightGBM model if it's a wrapper
                    if hasattr(best_model_obj, 'model') and best_model_obj.model is not None:
                        # It's a wrapper class, save the internal model
                        actual_model = best_model_obj.model
                    else:
                        # It's already the model itself
                        actual_model = best_model_obj
                    
                    # Use joblib to save the actual model
                    joblib.dump(actual_model, model_path)
                    
                    st.success(f"‚úÖ Model saved to {model_path}")
                    
                    # Download button
                    with open(model_path, 'rb') as f:
                        model_bytes = f.read()
                    
                    st.download_button(
                        label="üì• Download Best Model (Pickle)",
                        data=model_bytes,
                        file_name="best_esg_prediction_model.pkl",
                        mime="application/octet-stream"
                    )
                
                # Download predictions
                st.subheader("üìä Download Predictions")
                
                if st.session_state.regression_trainer:
                    # Create predictions DataFrame
                    predictions_df = pd.DataFrame({
                        'True_Value': model_results['true_values']['test'],
                        'Predicted_Value': model_results['predictions']['test'],
                        'Residual': model_results['true_values']['test'] - model_results['predictions']['test'],
                        'Absolute_Error': np.abs(model_results['true_values']['test'] - model_results['predictions']['test'])
                    })
                    
                    csv = predictions_df.to_csv(index=False)
                    st.download_button(
                        label="üì• Download Test Predictions (CSV)",
                        data=csv,
                        file_name="esg_predictions.csv",
                        mime="text/csv"
                    )
    
    # Tab 7: Comparaison Clustering
    with tab7:
        st.header("‚öñÔ∏è Comparaison: Avec vs Sans Clustering")
        
        # Check if both results are available
        sans_clustering_path = "prediction_sans_cls/metrics_sans_clustering.csv"
        avec_clustering_available = st.session_state.regression_results is not None
        
        if not os.path.exists(sans_clustering_path):
            st.warning("‚ö†Ô∏è **R√©sultats sans clustering non trouv√©s.**")
            st.info("üí° **Instructions**: Ex√©cutez d'abord `prediction_sans_cls/pretraitement.py` pour g√©n√©rer les m√©triques sans clustering.")
        elif not avec_clustering_available:
            st.warning("‚ö†Ô∏è **R√©sultats avec clustering non disponibles.**")
            st.info("üí° **Instructions**: Allez dans l'onglet 'üîÆ ESG Score Prediction' et entra√Ænez les mod√®les avec clustering.")
        else:
            # Load metrics without clustering
            metrics_sans_cls = pd.read_csv(sans_clustering_path)
            
            # Get metrics with clustering
            if st.session_state.regression_comparison_df is None:
                st.warning("‚ö†Ô∏è **R√©sultats avec clustering non disponibles.**")
                st.info("üí° **Instructions**: Allez dans l'onglet 'üîÆ ESG Score Prediction' et entra√Ænez les mod√®les avec clustering.")
            else:
                metrics_avec_cls = st.session_state.regression_comparison_df.copy()
                
                # Prepare comparison
                st.subheader("üìä Comparaison des M√©triques")
                
                # Create comparison table
                comparison_data = []
                
                # Get best model from clustering results
                best_model_cls = st.session_state.best_regression_model
                
                # Compare Random Forest
                r2_improvement_rf = None
                rmse_improvement_rf = None
                mae_improvement_rf = None
                rf_sans = metrics_sans_cls[metrics_sans_cls['Model'] == 'Random Forest (Sans Clustering)'].iloc[0]
                if 'Random Forest' in metrics_avec_cls['Model'].values:
                    rf_avec = metrics_avec_cls[metrics_avec_cls['Model'] == 'Random Forest'].iloc[0]
                    
                    # Calculate improvement
                    r2_improvement_rf = ((rf_avec['R¬≤ Score (Test)'] - rf_sans['R2_Score']) / abs(rf_sans['R2_Score'])) * 100 if rf_sans['R2_Score'] != 0 else 0
                    rmse_improvement_rf = ((rf_sans['RMSE'] - rf_avec['RMSE (Test)']) / rf_sans['RMSE']) * 100 if rf_sans['RMSE'] != 0 else 0
                    mae_improvement_rf = ((rf_sans['MAE'] - rf_avec['MAE (Test)']) / rf_sans['MAE']) * 100 if rf_sans['MAE'] != 0 else 0
                    
                    comparison_data.append({
                        'Mod√®le': 'Random Forest',
                        'M√©thode': 'Sans Clustering',
                        'R¬≤ Score': rf_sans['R2_Score'],
                        'RMSE': rf_sans['RMSE'],
                        'MAE': rf_sans['MAE'],
                        'MAPE (%)': rf_sans['MAPE']
                    })
                    comparison_data.append({
                        'Mod√®le': 'Random Forest',
                        'M√©thode': 'Avec Clustering',
                        'R¬≤ Score': rf_avec['R¬≤ Score (Test)'],
                        'RMSE': rf_avec['RMSE (Test)'],
                        'MAE': rf_avec['MAE (Test)'],
                        'MAPE (%)': rf_avec['MAPE (Test)']
                    })
                    comparison_data.append({
                        'Mod√®le': 'Random Forest',
                        'M√©thode': 'Am√©lioration (%)',
                        'R¬≤ Score': f"{r2_improvement_rf:+.2f}%",
                        'RMSE': f"{rmse_improvement_rf:+.2f}%",
                        'MAE': f"{mae_improvement_rf:+.2f}%",
                        'MAPE (%)': "-"
                    })
                
                # Compare XGBoost/LightGBM
                r2_improvement_lgbm = None
                rmse_improvement_lgbm = None
                mae_improvement_lgbm = None
                xgb_sans = metrics_sans_cls[metrics_sans_cls['Model'] == 'XGBoost (Sans Clustering)'].iloc[0]
                if 'LightGBM' in metrics_avec_cls['Model'].values:
                    lgbm_avec = metrics_avec_cls[metrics_avec_cls['Model'] == 'LightGBM'].iloc[0]
                    
                    r2_improvement_lgbm = ((lgbm_avec['R¬≤ Score (Test)'] - xgb_sans['R2_Score']) / abs(xgb_sans['R2_Score'])) * 100 if xgb_sans['R2_Score'] != 0 else 0
                    rmse_improvement_lgbm = ((xgb_sans['RMSE'] - lgbm_avec['RMSE (Test)']) / xgb_sans['RMSE']) * 100 if xgb_sans['RMSE'] != 0 else 0
                    mae_improvement_lgbm = ((xgb_sans['MAE'] - lgbm_avec['MAE (Test)']) / xgb_sans['MAE']) * 100 if xgb_sans['MAE'] != 0 else 0
                    
                    comparison_data.append({
                        'Mod√®le': 'XGBoost/LightGBM',
                        'M√©thode': 'Sans Clustering (XGBoost)',
                        'R¬≤ Score': xgb_sans['R2_Score'],
                        'RMSE': xgb_sans['RMSE'],
                        'MAE': xgb_sans['MAE'],
                        'MAPE (%)': xgb_sans['MAPE']
                    })
                    comparison_data.append({
                        'Mod√®le': 'XGBoost/LightGBM',
                        'M√©thode': 'Avec Clustering (LightGBM)',
                        'R¬≤ Score': lgbm_avec['R¬≤ Score (Test)'],
                        'RMSE': lgbm_avec['RMSE (Test)'],
                        'MAE': lgbm_avec['MAE (Test)'],
                        'MAPE (%)': lgbm_avec['MAPE (Test)']
                    })
                    comparison_data.append({
                        'Mod√®le': 'XGBoost/LightGBM',
                        'M√©thode': 'Am√©lioration (%)',
                        'R¬≤ Score': f"{r2_improvement_lgbm:+.2f}%",
                        'RMSE': f"{rmse_improvement_lgbm:+.2f}%",
                        'MAE': f"{mae_improvement_lgbm:+.2f}%",
                        'MAPE (%)': "-"
                    })
            
                comparison_df = pd.DataFrame(comparison_data)
                st.dataframe(comparison_df, use_container_width=True)
                
                st.divider()
                
                # Determine if clustering improved prediction
                st.subheader("üéØ Conclusion: Le Clustering a-t-il Am√©lior√© la Pr√©diction ?")
                
                # Analyze improvements
                improvements = []
                conclusions = []
                
                if 'Random Forest' in metrics_avec_cls['Model'].values and r2_improvement_rf is not None:
                    if r2_improvement_rf > 0:
                        improvements.append(f"‚úÖ **Random Forest**: R¬≤ am√©lior√© de {r2_improvement_rf:.2f}%")
                        conclusions.append("Random Forest: Clustering am√©liore la pr√©diction")
                    elif r2_improvement_rf < -1:
                        improvements.append(f"‚ùå **Random Forest**: R¬≤ diminu√© de {abs(r2_improvement_rf):.2f}%")
                        conclusions.append("Random Forest: Clustering n'am√©liore pas la pr√©diction")
                    else:
                        improvements.append(f"‚û°Ô∏è **Random Forest**: R¬≤ similaire ({r2_improvement_rf:+.2f}%)")
                        conclusions.append("Random Forest: Clustering n'a pas d'impact significatif")
            
                if 'LightGBM' in metrics_avec_cls['Model'].values and r2_improvement_lgbm is not None:
                    if r2_improvement_lgbm > 0:
                        improvements.append(f"‚úÖ **LightGBM**: R¬≤ am√©lior√© de {r2_improvement_lgbm:.2f}%")
                        conclusions.append("LightGBM: Clustering am√©liore la pr√©diction")
                    elif r2_improvement_lgbm < -1:
                        improvements.append(f"‚ùå **LightGBM**: R¬≤ diminu√© de {abs(r2_improvement_lgbm):.2f}%")
                        conclusions.append("LightGBM: Clustering n'am√©liore pas la pr√©diction")
                    else:
                        improvements.append(f"‚û°Ô∏è **LightGBM**: R¬≤ similaire ({r2_improvement_lgbm:+.2f}%)")
                        conclusions.append("LightGBM: Clustering n'a pas d'impact significatif")
                
                # Overall conclusion
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**Am√©liorations par Mod√®le:**")
                    for imp in improvements:
                        st.write(imp)
                
                with col2:
                    # Count positive vs negative
                    positive_count = sum(1 for c in conclusions if "am√©liore" in c)
                    negative_count = sum(1 for c in conclusions if "n'am√©liore pas" in c)
                    neutral_count = sum(1 for c in conclusions if "pas d'impact" in c)
                    
                    if positive_count > negative_count + neutral_count:
                        st.success("üéâ **CONCLUSION GLOBALE**: Le clustering **AM√âLIORE** la pr√©diction !")
                        st.balloons()
                    elif negative_count > positive_count + neutral_count:
                        st.error("‚ö†Ô∏è **CONCLUSION GLOBALE**: Le clustering **N'AM√âLIORE PAS** la pr√©diction.")
                    else:
                        st.info("‚û°Ô∏è **CONCLUSION GLOBALE**: Le clustering a un **IMPACT NEUTRE** sur la pr√©diction.")
                
                st.divider()
                
                # Visualizations
                st.subheader("üìà Visualisations Comparatives")
                
                # Create comparison charts
                col_viz1, col_viz2 = st.columns(2)
                
                with col_viz1:
                    # R¬≤ Score comparison
                    models_comp = []
                    r2_sans = []
                    r2_avec = []
                    
                    if 'Random Forest' in metrics_avec_cls['Model'].values and r2_improvement_rf is not None:
                        models_comp.append('Random Forest')
                        r2_sans.append(rf_sans['R2_Score'])
                        r2_avec.append(rf_avec['R¬≤ Score (Test)'])
                    
                    if 'LightGBM' in metrics_avec_cls['Model'].values and r2_improvement_lgbm is not None:
                        models_comp.append('XGBoost/LightGBM')
                        r2_sans.append(xgb_sans['R2_Score'])
                        r2_avec.append(lgbm_avec['R¬≤ Score (Test)'])
                    
                    fig_r2 = go.Figure()
                    fig_r2.add_trace(go.Bar(
                        name='Sans Clustering',
                        x=models_comp,
                        y=r2_sans,
                        marker_color='lightblue'
                    ))
                    fig_r2.add_trace(go.Bar(
                        name='Avec Clustering',
                        x=models_comp,
                        y=r2_avec,
                        marker_color='lightgreen'
                    ))
                    fig_r2.update_layout(
                        title="Comparaison R¬≤ Score",
                        xaxis_title="Mod√®le",
                        yaxis_title="R¬≤ Score",
                        barmode='group'
                    )
                    st.plotly_chart(fig_r2, use_container_width=True)
                
                with col_viz2:
                    # RMSE comparison
                    rmse_sans = []
                    rmse_avec = []
                    
                    if 'Random Forest' in metrics_avec_cls['Model'].values and r2_improvement_rf is not None:
                        rmse_sans.append(rf_sans['RMSE'])
                        rmse_avec.append(rf_avec['RMSE (Test)'])
                    
                    if 'LightGBM' in metrics_avec_cls['Model'].values and r2_improvement_lgbm is not None:
                        rmse_sans.append(xgb_sans['RMSE'])
                        rmse_avec.append(lgbm_avec['RMSE (Test)'])
                    
                    fig_rmse = go.Figure()
                    fig_rmse.add_trace(go.Bar(
                        name='Sans Clustering',
                        x=models_comp,
                        y=rmse_sans,
                        marker_color='lightcoral'
                    ))
                    fig_rmse.add_trace(go.Bar(
                        name='Avec Clustering',
                        x=models_comp,
                        y=rmse_avec,
                        marker_color='lightgreen'
                    ))
                    fig_rmse.update_layout(
                        title="Comparaison RMSE (plus bas = mieux)",
                        xaxis_title="Mod√®le",
                        yaxis_title="RMSE",
                        barmode='group'
                    )
                    st.plotly_chart(fig_rmse, use_container_width=True)
                
                # MAE comparison
                col_viz3, col_viz4 = st.columns(2)
                
                with col_viz3:
                    mae_sans = []
                    mae_avec = []
                    
                    if 'Random Forest' in metrics_avec_cls['Model'].values and r2_improvement_rf is not None:
                        mae_sans.append(rf_sans['MAE'])
                        mae_avec.append(rf_avec['MAE (Test)'])
                    
                    if 'LightGBM' in metrics_avec_cls['Model'].values and r2_improvement_lgbm is not None:
                        mae_sans.append(xgb_sans['MAE'])
                        mae_avec.append(lgbm_avec['MAE (Test)'])
                    
                    fig_mae = go.Figure()
                    fig_mae.add_trace(go.Bar(
                        name='Sans Clustering',
                        x=models_comp,
                        y=mae_sans,
                        marker_color='lightsalmon'
                    ))
                    fig_mae.add_trace(go.Bar(
                        name='Avec Clustering',
                        x=models_comp,
                        y=mae_avec,
                        marker_color='lightgreen'
                    ))
                    fig_mae.update_layout(
                        title="Comparaison MAE (plus bas = mieux)",
                        xaxis_title="Mod√®le",
                        yaxis_title="MAE",
                        barmode='group'
                    )
                    st.plotly_chart(fig_mae, use_container_width=True)
                
                with col_viz4:
                    # Improvement percentage chart
                    improvements_r2 = []
                    improvements_rmse = []
                    
                    if 'Random Forest' in metrics_avec_cls['Model'].values and r2_improvement_rf is not None:
                        improvements_r2.append(r2_improvement_rf)
                        improvements_rmse.append(rmse_improvement_rf)
                    
                    if 'LightGBM' in metrics_avec_cls['Model'].values and r2_improvement_lgbm is not None:
                        improvements_r2.append(r2_improvement_lgbm)
                        improvements_rmse.append(rmse_improvement_lgbm)
                    
                    fig_improvement = go.Figure()
                    fig_improvement.add_trace(go.Bar(
                        name='R¬≤ Am√©lioration (%)',
                        x=models_comp,
                        y=improvements_r2,
                        marker_color='green' if all(x > 0 for x in improvements_r2) else 'red' if all(x < 0 for x in improvements_r2) else 'orange'
                    ))
                    fig_improvement.add_hline(y=0, line_dash="dash", line_color="gray")
                    fig_improvement.update_layout(
                        title="Am√©lioration avec Clustering (%)",
                        xaxis_title="Mod√®le",
                        yaxis_title="Am√©lioration (%)",
                        barmode='group'
                    )
                    st.plotly_chart(fig_improvement, use_container_width=True)
                
                st.divider()
                
                # Download comparison
                st.subheader("üíæ T√©l√©charger la Comparaison")
                comparison_csv = comparison_df.to_csv(index=False)
                st.download_button(
                    label="üì• T√©l√©charger Comparaison (CSV)",
                    data=comparison_csv,
                    file_name="comparaison_clustering.csv",
                    mime="text/csv"
                )
    
    # Tab 8: Interpr√©tabilit√© XAI (SHAP + PDP)
    with tab8:
        st.header("üß† Interpr√©tabilit√© du Meilleur Mod√®le (XAI)")
        
        trainer = st.session_state.get("regression_trainer")
        best_model_name = st.session_state.get("best_regression_model")
        regression_results = st.session_state.get("regression_results", {})
        
        if (
            trainer is not None
            and best_model_name is not None
            and best_model_name in regression_results
        ):
            best_model_wrapper = regression_results[best_model_name]["model"]
            
            # Extract the underlying model from the wrapper class
            if hasattr(best_model_wrapper, 'model') and best_model_wrapper.model is not None:
                # It's a wrapper class (RandomForestRegressorModel or LightGBMRegressorModel)
                actual_model = best_model_wrapper.model
            else:
                # It's already the model itself
                actual_model = best_model_wrapper
            
            st.success(f"‚úÖ Mod√®le analys√©: **{best_model_name}**")
            
            st.markdown("""
            Cette section vous permet d'analyser et d'interpr√©ter les pr√©dictions du meilleur mod√®le 
            √† l'aide de deux techniques compl√©mentaires d'IA explicable (XAI):
            
            - **SHAP (SHapley Additive exPlanations)**: Explique la contribution de chaque variable √† une pr√©diction
            - **PDP (Partial Dependence Plots)**: Montre l'effet marginal des variables, y compris l'impact des clusters
            """)
            
            st.divider()
            
            # Cr√©er des onglets pour SHAP et PDP
            tab_shap, tab_pdp = st.tabs(["üìä SHAP Analysis", "üìà Partial Dependence Plots (PDP)"])
            
            with tab_shap:
                st.markdown("### üìä SHAP - Explication des Pr√©dictions")
                st.info("""
                **SHAP** (SHapley Additive exPlanations) explique la contribution de chaque variable 
                √† une pr√©diction sp√©cifique en attribuant une valeur d'importance bas√©e sur la th√©orie des jeux.
                
                **Utilisations:**
                - Identifier les variables les plus influentes
                - Comprendre les pr√©dictions individuelles
                - D√©tecter les biais du mod√®le
                """)
                render_shap_dashboard(actual_model, trainer)
            
            with tab_pdp:
                render_pdp_analysis(actual_model, trainer, best_model_name)
        
        else:
            st.warning(
                "‚ö†Ô∏è Aucun mod√®le entra√Æn√© pour le moment.\n\n"
                "Veuillez entra√Æner un mod√®le de r√©gression dans l'onglet 'üîÆ ESG Score Prediction' "
                "afin d'afficher l'analyse d'interpr√©tabilit√© (SHAP + PDP)."
            )
            
            st.info("""
            **üí° Instructions:**
            
            1. Allez dans l'onglet **üîÆ ESG Score Prediction**
            2. Configurez et entra√Ænez un mod√®le (Random Forest ou LightGBM)
            3. Assurez-vous d'activer **"Include Cluster Labels"** pour analyser l'impact du clustering
            4. Revenez ici pour voir les analyses SHAP et PDP
            """)
    
    # Clear cache
    if clear_cache_btn:
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

if __name__ == "__main__":
    main()
