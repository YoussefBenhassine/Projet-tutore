# Sélection et configuration des modèles

Pour la prédiction des scores ESG sur les données clusterisées, deux algorithmes d'apprentissage supervisé ont été sélectionnés : le Random Forest Regressor et le LightGBM Regressor. Ces modèles ont été choisis pour leur capacité à gérer des relations non-linéaires complexes et leur robustesse face aux données hétérogènes caractéristiques des métriques ESG. La configuration des hyperparamètres a été réalisée de manière systématique via une optimisation bayésienne utilisant la bibliothèque Optuna, permettant d'explorer efficacement l'espace des paramètres tout en minimisant le risque de surajustement. Pour le Random Forest, les hyperparamètres optimisés incluent le nombre d'estimateurs (n_estimators : 50-300), la profondeur maximale des arbres (max_depth : 3-20), les seuils minimaux d'échantillons pour les splits et les feuilles (min_samples_split : 2-20, min_samples_leaf : 1-10), ainsi que le nombre maximal de features considérées à chaque split (max_features : 'sqrt', 'log2', None) et l'utilisation du bootstrap. Concernant LightGBM, l'optimisation porte sur le nombre d'estimateurs (50-300), la profondeur maximale (3-15), le taux d'apprentissage (learning_rate : 0.01-0.3, échelle logarithmique), le nombre de feuilles (num_leaves : 10-100), les échantillons minimaux par enfant (min_child_samples : 5-50), les taux d'échantillonnage des lignes et colonnes (subsample : 0.6-1.0, colsample_bytree : 0.6-1.0), ainsi que les termes de régularisation L1 et L2 (reg_alpha et reg_lambda : 0.0-1.0). L'optimisation est effectuée via une validation croisée à K plis (K=5 par défaut) avec un découpage stratifié, utilisant l'erreur quadratique moyenne (MSE) comme métrique d'optimisation. Les données sont préalablement divisées en ensembles d'entraînement (80%) et de test (20%) avec une graine aléatoire fixe (random_state=42) pour assurer la reproductibilité. Les labels de cluster issus de l'étape de clustering sont intégrés comme features additionnelles, permettant aux modèles de bénéficier de l'information structurelle dérivée de la similarité entre entreprises. Chaque modèle est évalué sur les deux ensembles (entraînement et test) ainsi qu'en validation croisée, avec le calcul de métriques complémentaires incluant le coefficient de détermination R², la racine de l'erreur quadratique moyenne (RMSE), l'erreur absolue moyenne (MAE) et l'erreur absolue moyenne en pourcentage (MAPE), offrant ainsi une évaluation robuste et multidimensionnelle de la performance prédictive.
